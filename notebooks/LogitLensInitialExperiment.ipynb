{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67160ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, baukit\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "MODEL_NAME = \"gpt2-xl\"  # gpt2-xl or EleutherAI/gpt-j-6B\n",
    "model, tok = (\n",
    "    AutoModelForCausalLM.from_pretrained(MODEL_NAME, low_cpu_mem_usage=False).to(\"cuda\"),\n",
    "    AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd93e63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ccc72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = {k: torch.tensor(v)[None].cuda() for k, v in tok('Hello - nice to meet you.  My full name is David Bau.  I work as a software engineer at a company located in the').items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e822dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83680ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "baukit.set_requires_grad(False, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e480ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(**input)['logits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a81756",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_scores = logits[0, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2756240",
   "metadata": {},
   "outputs": [],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440d3266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, tok, prefix, n=10):\n",
    "    inp = {k: torch.tensor(v)[None].cuda() for k, v in tok(prefix).items()}\n",
    "    initial_length = len(inp['input_ids'])\n",
    "    pkv = None\n",
    "    for _ in range(n):\n",
    "        full_out = model(**inp)\n",
    "        out = full_out['logits']\n",
    "        pred = out[0, -1].argmax()\n",
    "        inp['input_ids'] = torch.cat((inp['input_ids'], torch.tensor([pred])[None].cuda()), dim=1)\n",
    "        inp['attention_mask'] = torch.cat((inp['attention_mask'], torch.ones(1, 1).cuda()), dim=1)\n",
    "    return tok.decode(inp['input_ids'][0, initial_length:])\n",
    "generate(model, tok, 'In his NBA career, KC Jones played', n=100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2989295d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baukit import TraceDict\n",
    "\n",
    "def get_hidden_states(model, tok, prefix, layers=[]):\n",
    "    inp = {k: torch.tensor(v)[None].cuda() for k, v in tok(prefix).items()}\n",
    "    layer_names = [f'transformer.h.{i}' for i in layers]\n",
    "    with TraceDict(model, layer_names) as tr:\n",
    "        logits = model(**inp)['logits']\n",
    "    return torch.stack([tr[ln].output[0] for ln in layer_names])\n",
    "\n",
    "prompt = 'Hello, my name is also'\n",
    "hs = get_hidden_states(model, tok, prompt, list(range(48)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aff42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_logit_lens(model, tok, prefix, layers=None, topk=5, color=None, hs=None):\n",
    "    from baukit import show\n",
    "\n",
    "    if layers is None:\n",
    "        layers = list(reversed(range(len(hs) if hs is not None else 48)))\n",
    "    if hs is None:\n",
    "        hs = get_hidden_states(model, tok, prefix, layers)\n",
    "    decoder = torch.nn.Sequential(model.transformer.ln_f, model.lm_head)\n",
    "    prompt_tokens = [tok.decode(t) for t in tok.encode(prefix)]\n",
    "    probs = torch.nn.functional.softmax(decoder(hs), dim=-1)\n",
    "    favorite_probs, favorite_tokens = probs.topk(k=topk, dim=-1)\n",
    "    def default_color(p):\n",
    "        return show.style(background=f'rgb({int(255 * (1-p))}, 255, {int(255 * (1-p))})')\n",
    "    if color is None:\n",
    "        color = default_color\n",
    "    def hover(tok, prob, toks):\n",
    "        lines = []\n",
    "        for p, t in zip(prob, toks):\n",
    "            lines.append(f'{tok.decode(t)}: prob {p:.2f}')\n",
    "        return show.attr(title='\\n'.join(lines))\n",
    "    show([ # header line\n",
    "             [show.style(fontWeight='bold'), 'Layer'] +\n",
    "             [\n",
    "                 [show.style(background='yellow'), t]\n",
    "                 for t in prompt_tokens\n",
    "             ]\n",
    "         ] +  \n",
    "         # body\n",
    "         [\n",
    "             # first column\n",
    "             [show.style(fontWeight='bold'), layer] +\n",
    "             [\n",
    "                 # subsequent columns\n",
    "                 [color(p[0]), hover(tok, p, t), tok.decode(t[0])]\n",
    "                 for p, t in zip(wordprobs, words)\n",
    "             ]\n",
    "         for layer, wordprobs, words in zip(layers, favorite_probs[:, 0], favorite_tokens[:,0])]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bbda64",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_logit_lens(model, tok, 'The biggest city in New England is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9249e5a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_hidden_state_deltas(model, tok, prefix, layers=None):\n",
    "    if layers is None:\n",
    "        layers = list(range(48))\n",
    "    inp = {k: torch.tensor(v)[None].cuda() for k, v in tok(prefix).items()}\n",
    "    layer_names = ['transformer.drop'] + [f'transformer.h.{i}' for i in layers]\n",
    "    with TraceDict(model, layer_names) as tr:\n",
    "        logits = model(**inp)['logits']\n",
    "    first_h = tr['transformer.drop'].output[None]\n",
    "    other_h = torch.stack([tr[ln].output[0] for ln in layer_names[1:]])\n",
    "    all_h = torch.cat([first_h, other_h])\n",
    "    delta_h = all_h[1:] - all_h[:-1]\n",
    "    return delta_h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590a795b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = get_hidden_state_deltas(model, tok, 'The biggest city in New England is')\n",
    "hs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e932ef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_logit_lens(model, tok, 'The biggest city in New England is', hs=hs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6e4e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = torch.nn.functional.softmax(decoder(hs), dim=-1)\n",
    "favorite_probs, favorite_tokens = probs.topk(k=5, dim=-1)\n",
    "favorite_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96338a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color(p):\n",
    "    return show.style(background=f'rgb({int(255 * (1-p))}, 255, {int(255 * (1-p))})')\n",
    "def hover(tok, prob, toks):\n",
    "    lines = []\n",
    "    for p, t in zip(prob, toks):\n",
    "        lines.append(f'{tok.decode(t)}: prob {p:.2f}')\n",
    "    return show.attr(title='\\n'.join(lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bef395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baukit import show\n",
    "\n",
    "show([[[show.style(background='yellow'), t] for t in prompt_tokens]] +     \n",
    "     [[[color(p[0]), hover(tok, p, t), tok.decode(t[0])] for p, t in zip(wordprobs, words)]\n",
    "       for wordprobs, words in zip(favorite_probs[:, 0], favorite_tokens[:,0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7efa817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd31f117",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr['transformer.h.10'].output[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f85b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "(torch.Size([1, 5, 1600]),\n",
    " (torch.Size([1, 25, 5, 64]\n",
    "  torch.Size([1, 25, 5, 64])\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852638f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(**input)\n",
    "list(out.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e227367",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(model.forward)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
