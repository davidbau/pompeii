{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe75c380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, baukit\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "MODEL_NAME = \"gpt2-xl\"  # gpt2-xl or EleutherAI/gpt-j-6B\n",
    "model, tok = (\n",
    "    AutoModelForCausalLM.from_pretrained(MODEL_NAME, low_cpu_mem_usage=False).to(\"cuda\"),\n",
    "    AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af262664",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e1855f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = {k: torch.tensor(v)[None].cuda() for k, v in tok('Hello - nice to meet you.  My full name is David Bau.  I work as a software engineer at a company located in the').items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64820a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ff5efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "baukit.set_requires_grad(False, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efece66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(**input)['logits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cd1255",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_scores = logits[0, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5896261",
   "metadata": {},
   "outputs": [],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7831ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, tok, prefix, n=10):\n",
    "    inp = {k: torch.tensor(v)[None].cuda() for k, v in tok(prefix).items()}\n",
    "    initial_length = len(inp['input_ids'])\n",
    "    pkv = None\n",
    "    for _ in range(n):\n",
    "        full_out = model(**inp)\n",
    "        out = full_out['logits']\n",
    "        pred = out[0, -1].argmax()\n",
    "        inp['input_ids'] = torch.cat((inp['input_ids'], torch.tensor([pred])[None].cuda()), dim=1)\n",
    "        inp['attention_mask'] = torch.cat((inp['attention_mask'], torch.ones(1, 1).cuda()), dim=1)\n",
    "    return tok.decode(inp['input_ids'][0, initial_length:])\n",
    "generate(model, tok, 'In his NBA career, KC Jones played', n=100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf57b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baukit import TraceDict\n",
    "\n",
    "def get_hidden_states(model, tok, prefix, layers=[]):\n",
    "    inp = {k: torch.tensor(v)[None].cuda() for k, v in tok(prefix).items()}\n",
    "    layer_names = [f'transformer.h.{i}' for i in layers]\n",
    "    with TraceDict(model, layer_names) as tr:\n",
    "        logits = model(**inp)['logits']\n",
    "    return torch.stack([tr[ln].output[0] for ln in layer_names])\n",
    "\n",
    "prompt = 'Hello, my name is also'\n",
    "hs = get_hidden_states(model, tok, prompt, list(range(48)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6218d6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_logit_lens(model, tok, prefix, layers=None, topk=5, color=None, hs=None):\n",
    "    from baukit import show\n",
    "    import re\n",
    "    if layers is None:\n",
    "        layers = list(range(\n",
    "            len([n for n, _ in model.named_modules()\n",
    "             if re.match('^transformer.h.\\d+$', n)])))\n",
    "    if hs is None:\n",
    "        hs = get_hidden_states(model, tok, prefix, layers)\n",
    "    elif callable(hs):\n",
    "        hs = hs(model, tok, prefix, layers)\n",
    "    decoder = torch.nn.Sequential(model.transformer.ln_f, model.lm_head)\n",
    "    prompt_tokens = [tok.decode(t) for t in tok.encode(prefix)]\n",
    "    probs = torch.nn.functional.softmax(decoder(hs), dim=-1)\n",
    "    favorite_probs, favorite_tokens = probs.topk(k=topk, dim=-1)\n",
    "    if color is None:\n",
    "        color = [0, 0, 255]\n",
    "    def color_fn(p):\n",
    "        a = [int(255 * (1-p) + c * p) for c in color]\n",
    "        return show.style(background=f'rgb({a[0]}, {a[1]}, {a[2]})')\n",
    "    def hover(tok, prob, toks):\n",
    "        lines = []\n",
    "        for p, t in zip(prob, toks):\n",
    "            lines.append(f'{tok.decode(t)}: prob {p:.2f}')\n",
    "        return show.attr(title='\\n'.join(lines))\n",
    "    def make_button_with_cb(text, layer, tok):\n",
    "        def clickme():\n",
    "            print(layer, tok)\n",
    "        return baukit.Button(text).on('click', clickme)\n",
    "    header_line = [ # header line\n",
    "             [show.style(fontWeight='bold'), 'Layer'] +\n",
    "             [\n",
    "                 [show.style(background='yellow'), t]\n",
    "                 for t in prompt_tokens\n",
    "             ]\n",
    "         ]\n",
    "    layout = [header_line,\n",
    "         # body\n",
    "         [\n",
    "             # first column\n",
    "             [show.style(fontWeight='bold'), layer] +\n",
    "             [\n",
    "                 # subsequent columns\n",
    "                 [color_fn(p[0]), hover(tok, p, t), make_button_with_cb(tok.decode(t[0]), layer, tok.decode(t[0]))]\n",
    "                 for p, t in zip(wordprobs, words)\n",
    "             ]\n",
    "         for layer, wordprobs, words in zip(layers, favorite_probs[:, 0], favorite_tokens[:,0])],\n",
    "         header_line\n",
    "             ]\n",
    "    show(*layout)\n",
    "    return layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8849c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = show_logit_lens(model, tok, 'The biggest city in New England is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904c7c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout[1][47][3][-1].label = 'hello'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c7c5b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_hidden_state_deltas(model, tok, prefix, layers=None):\n",
    "    if layers is None:\n",
    "        layers = list(range(48))\n",
    "    inp = {k: torch.tensor(v)[None].cuda() for k, v in tok(prefix).items()}\n",
    "    layer_names =  [f'transformer.h.{i}' for i in layers]\n",
    "    with TraceDict(model, ['transformer.drop'] + layer_names) as tr:\n",
    "        logits = model(**inp)['logits']\n",
    "    first_h = tr['transformer.drop'].output[None]\n",
    "    other_h = torch.stack([tr[ln].output[0] for ln in layer_names])\n",
    "    all_h = torch.cat([first_h, other_h])\n",
    "    delta_h = all_h[1:] - all_h[:-1]\n",
    "    return delta_h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0ff0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_logit_lens(model, tok, 'The biggest city in New England is',\n",
    "                hs=get_hidden_state_deltas, color=[255, 0, 255])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
