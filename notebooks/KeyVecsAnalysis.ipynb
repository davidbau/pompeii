{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1d16ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /share/u/koyena/.conda/envs/rome/lib/python3.9/site-packages (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /share/u/koyena/.conda/envs/rome/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /share/u/koyena/.conda/envs/rome/lib/python3.9/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /share/u/koyena/.conda/envs/rome/lib/python3.9/site-packages (from pandas) (1.23.1)\n",
      "Requirement already satisfied: six>=1.5 in /share/u/koyena/.conda/envs/rome/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: sklearn in /share/u/koyena/.conda/envs/rome/lib/python3.9/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /share/u/koyena/.conda/envs/rome/lib/python3.9/site-packages (from sklearn) (1.1.2)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /share/u/koyena/.conda/envs/rome/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /share/u/koyena/.conda/envs/rome/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.23.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /share/u/koyena/.conda/envs/rome/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.9.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /share/u/koyena/.conda/envs/rome/lib/python3.9/site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: umap-learn in /share/u/koyena/.conda/envs/rome/lib/python3.9/site-packages (0.5.3)\n",
      "Requirement already satisfied: numba>=0.49 in /share/u/koyena/.conda/envs/rome/lib/python3.9/site-packages (from umap-learn) (0.56.3)\n",
      "Requirement already satisfied: scipy>=1.0 in /share/u/koyena/.conda/envs/rome/lib/python3.9/site-packages (from umap-learn) (1.9.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /share/u/koyena/.conda/envs/rome/lib/python3.9/site-packages (from umap-learn) (1.23.1)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /share/u/koyena/.conda/envs/rome/lib/python3.9/site-packages (from umap-learn) (0.5.8)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /share/u/koyena/.conda/envs/rome/lib/python3.9/site-packages (from umap-learn) (1.1.2)\n",
      "Requirement already satisfied: tqdm in /share/u/koyena/.conda/envs/rome/lib/python3.9/site-packages (from umap-learn) (4.64.1)\n",
      "Requirement already satisfied: setuptools in /share/u/koyena/.conda/envs/rome/lib/python3.9/site-packages (from numba>=0.49->umap-learn) (61.2.0)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /share/u/koyena/.conda/envs/rome/lib/python3.9/site-packages (from numba>=0.49->umap-learn) (0.39.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /share/u/koyena/.conda/envs/rome/lib/python3.9/site-packages (from pynndescent>=0.5->umap-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /share/u/koyena/.conda/envs/rome/lib/python3.9/site-packages (from scikit-learn>=0.22->umap-learn) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install sklearn\n",
    "!pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8adc4c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/u/koyena/.conda/envs/rome/lib/python3.9/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: /share/u/koyena/.conda/envs/rome/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch, baukit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from baukit import pbar\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c9e3df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_euclidean(x, y):\n",
    "    return np.sqrt(np.sum((x-y)**2))\n",
    "\n",
    "def get_dists(origin,all_vecs):\n",
    "    dists = np.empty(len(all_vecs))\n",
    "    for v in range(len(all_vecs)):\n",
    "    #for v in pbar(range(len(all_vecs))):\n",
    "        dist = compute_euclidean(origin,all_vecs[v])\n",
    "        dists[v] = dist\n",
    "    return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88f069fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension reduction - pca / umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d111b78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_csv = \"../data/tokens.csv\"\n",
    "token_df = pd.read_csv(token_csv)\n",
    "tokens = token_df['token'].values\n",
    "token_types = token_df['token_type'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df2034a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "npy_datapath = \"../data/npy_files\"\n",
    "npy_files = os.listdir(npy_datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce4e9888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa23c681500e487cb63a6f6b30c8c1e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def find_k_closest_points(origin_index, all_vecs, tokens, k=1):\n",
    "    dists = get_dists(all_vecs[origin_index], all_vecs)\n",
    "    sorted_ind = np.argsort(dists)\n",
    "    k_counter = 0\n",
    "    k_points = []\n",
    "    for index in sorted_ind:\n",
    "        if index == origin_index:\n",
    "            continue\n",
    "        else:\n",
    "            if (k_counter < k):\n",
    "                k_points.append([tokens[index], index])\n",
    "                k_counter += 1\n",
    "    return k_points\n",
    "\n",
    "\n",
    "layer_names = []\n",
    "source_tokens = []\n",
    "source_token_types = []\n",
    "closest_tokens = []\n",
    "closest_token_types = []\n",
    "top_k_values = []\n",
    "for curr_file in pbar(npy_files):\n",
    "    curr_layer_path = npy_datapath + '/'+ curr_file\n",
    "    curr_layer_mats = np.load(curr_layer_path)\n",
    "    layer_name = curr_file.split('.')[0]\n",
    "    for t in range(len(tokens)):\n",
    "        k_points = find_k_closest_points(t, curr_layer_mats, tokens)\n",
    "        for i in range(len(k_points)):\n",
    "            \n",
    "            layer_names.append(layer_name)\n",
    "            source_tokens.append(tokens[t])\n",
    "            source_token_types.append(token_types[t])\n",
    "            closest_tokens.append(k_points[i][0])\n",
    "            closest_token_types.append(token_types[k_points[i][1]])\n",
    "            top_k_values.append(i)\n",
    "\n",
    "closest_df = pd.DataFrame({\"LayerName\": layer_names,\n",
    "                          \"SourceToken\": source_tokens,\n",
    "                          \"SourceTokenType\": source_token_types,\n",
    "                          \"ClosestToken\": closest_tokens,\n",
    "                          \"ClosestTokenType\": closest_token_types,\n",
    "                          \"TopK\": top_k_values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972bb20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "2022-11-02 16:56:34.032231: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-02 16:56:37.123169: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from umap import UMAP\n",
    "import plotly.express as px\n",
    "\n",
    "def project_key_vecs_umap(all_vecs, tokens, token_types):\n",
    "    umap_2d = UMAP(n_components=2, init=\"random\", random_state = 0)\n",
    "    projections = umap_2d.fit_transform(all_vecs)\n",
    "    df = pd.DataFrame()\n",
    "    df[\"tokens\"] = tokens\n",
    "    df[\"token_types\"] = token_types\n",
    "    df[\"comp-1\"] = projections[:,0]\n",
    "    df[\"comp-2\"] = projections[:,1]\n",
    "    \n",
    "    fig = px.scatter(\n",
    "    df, x=\"comp-1\", y=\"comp-2\",\n",
    "    color=\"token_types\", hover_data=[\"tokens\"],labels={\"color\": \"token_types\"})\n",
    "    fig.show()\n",
    "    \n",
    "curr_layer_path = npy_datapath + '/'+ npy_files[0]\n",
    "curr_layer_mats = np.load(curr_layer_path)\n",
    "project_key_vecs_umap(curr_layer_mats, tokens, token_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542f8124",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import plotly.express as px\n",
    "\n",
    "def project_key_vecs_tsne(all_vecs, tokens, token_types):\n",
    "\n",
    "#     vec_df = pd.DataFrame({\"KeyVec\": all_vecs, \"Token\": tokens, \"TokenType\": token_types})\n",
    "    tsne = TSNE(n_components=2, random_state = 0)\n",
    "    projections = tsne.fit_transform(all_vecs)\n",
    "    df = pd.DataFrame()\n",
    "    df[\"tokens\"] = tokens\n",
    "    df[\"token_types\"] = token_types\n",
    "    df[\"comp-1\"] = projections[:,0]\n",
    "    df[\"comp-2\"] = projections[:,1]\n",
    "    \n",
    "    fig = px.scatter(\n",
    "    df, x=\"comp-1\", y=\"comp-2\",\n",
    "    color=\"token_types\", hover_data=[\"tokens\"],labels={\"color\": \"token_types\"})\n",
    "    fig.show()\n",
    "    \n",
    "curr_layer_path = npy_datapath + '/'+ npy_files[0]\n",
    "curr_layer_mats = np.load(curr_layer_path)\n",
    "project_key_vecs_tsne(curr_layer_mats, tokens, token_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e2c870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token Type closeness\n",
    "type_df = closest_df[[\"LayerName\", \"SourceTokenType\", \"ClosestTokenType\"]]\n",
    "\n",
    "layers = []\n",
    "celeb_to_common_count = []\n",
    "celeb_to_celeb_count = []\n",
    "common_to_celeb_count = []\n",
    "common_to_common_count = []\n",
    "\n",
    "N = 48\n",
    "ind = np.arange(N) \n",
    "width = 0.25\n",
    "\n",
    "\n",
    "for i in range(48):\n",
    "    layer_name = \"transformer-h-\" + str(i)\n",
    "    layers.append(str(i))\n",
    "    celeb_to_common = ((type_df[\"LayerName\"] == layer_name) & \n",
    "                       (type_df[\"SourceTokenType\"] == \"celeb_people\") & \n",
    "                       (type_df[\"ClosestTokenType\"] == \"common_people\"))\n",
    "    celeb_to_celeb = ((type_df[\"LayerName\"] == layer_name) & \n",
    "                      (type_df[\"SourceTokenType\"] == \"celeb_people\") & \n",
    "                      (type_df[\"ClosestTokenType\"] == \"celeb_people\"))\n",
    "    common_to_celeb = ((type_df[\"LayerName\"] == layer_name) & \n",
    "                       (type_df[\"SourceTokenType\"] == \"common_people\") & \n",
    "                       (type_df[\"ClosestTokenType\"] == \"celeb_people\"))\n",
    "    common_to_common = ((type_df[\"LayerName\"] == layer_name) & \n",
    "                       (type_df[\"SourceTokenType\"] == \"common_people\") & \n",
    "                       (type_df[\"ClosestTokenType\"] == \"common_people\"))\n",
    "    \n",
    "    celeb_to_common_count.append(len(type_df[celeb_to_common] == True))\n",
    "    celeb_to_celeb_count.append(len(type_df[celeb_to_celeb] == True))\n",
    "    common_to_celeb_count.append(len(type_df[common_to_celeb] == True))\n",
    "    common_to_common_count.append(len(type_df[common_to_common] == True))\n",
    "    \n",
    "f = plt.figure()\n",
    "f.set_figwidth(20)\n",
    "f.set_figheight(10)\n",
    "\n",
    "bar1 = plt.bar(ind, celeb_to_common_count, width, color = 'blue')\n",
    "bar2 = plt.bar(ind+width, celeb_to_celeb_count, width, color='green')\n",
    "bar3 = plt.bar(ind+width*2, common_to_celeb_count, width, color = 'orange')\n",
    "bar4 = plt.bar(ind+width*3, common_to_celeb_count, width, color = 'red')\n",
    "\n",
    "plt.xlabel(\"Layer\")\n",
    "plt.ylabel('Frequency')\n",
    "plt.title(\"Closeness based on Token Type\")\n",
    "  \n",
    "plt.xticks(ind+width,layers)\n",
    "plt.legend( (bar1, bar2, bar3, bar4), ('celeb to common', 'celeb to celeb', 'common to celeb', 'common to common'))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc386c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token Type closeness\n",
    "synt_df = closest_df[[\"LayerName\", \"SourceToken\", \"ClosestToken\"]]\n",
    "\n",
    "layers = []\n",
    "similar_count = []\n",
    "diff_count = []\n",
    "\n",
    "N = 48\n",
    "ind = np.arange(N) \n",
    "width = 0.4\n",
    "\n",
    "\n",
    "for i in range(48):\n",
    "    layer_name = \"transformer-h-\" + str(i)\n",
    "    layers.append(str(i))\n",
    "    curr_layer_df = synt_df[synt_df[\"LayerName\"] == layer_name]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b47ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55351ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#erdish...degree of separation\n",
    "\n",
    "#contrastive\n",
    "\n",
    "#wikidata\n",
    "\n",
    "#occupation\n",
    "#gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95f7f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#two entity combined\n",
    "\n",
    "\n",
    "\n",
    "# famous sports player"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
